from google.colab import drive

# Mount to a new folder so we don't hit the "mountpoint not empty" error
drive.mount('/content/drive2')

# Then list the contents to check
!ls /content/drive2/MyDrive/

import os
import random
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# -----------------------------
# 1Ô∏è‚É£ Set seeds
# -----------------------------
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# -----------------------------
# 2Ô∏è‚É£ Load dataset
# -----------------------------
DATA_DIR = '/content/drive2/MyDrive/IoTvulCode/data/iDetectRefine'
csv_path = os.path.join(DATA_DIR, 'DNN-binary.csv')
if not os.path.exists(csv_path):
    raise FileNotFoundError(f"Expected dataset at {csv_path}")
df = pd.read_csv(csv_path, low_memory=False)

# -----------------------------
# 3Ô∏è‚É£ Preprocessing
# -----------------------------
X_text = df.iloc[:, :-1].astype(str).agg(' '.join, axis=1)
y_raw = df.iloc[:, -1].values

# Clean text
X_text = X_text.str.replace(r'\r\n|\r|\n', ' ', regex=True)
X_text = X_text.str.replace(r'\s+', ' ', regex=True)
X_text = X_text.str.replace(r'([{}()\[\].,;:+\-*/=&|<>%!~^])', r' \1 ', regex=True)
X_text = X_text.str.lower()

# Label encoding
le = LabelEncoder()
y_int = le.fit_transform(y_raw)
if len(np.unique(y_int)) != 2:
    raise ValueError("Expected binary classification labels but found multiple classes.")

# -----------------------------
# 4Ô∏è‚É£ Tokenization & padding
# -----------------------------
MAX_WORDS = 60000
SEQ_LEN = 300
EMB_DIM = 128
RNN_UNITS = 128
BATCH_SIZE = 128
EPOCHS = 6

tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='[OOV]', filters='')
tokenizer.fit_on_texts(X_text)
sequences = tokenizer.texts_to_sequences(X_text)
X_pad = pad_sequences(sequences, maxlen=SEQ_LEN, padding='post', truncating='post')
vocab_size = min(MAX_WORDS, len(tokenizer.word_index) + 1)

# -----------------------------
# 5Ô∏è‚É£ Train/Validation split
# -----------------------------
X_train, X_val, y_train, y_val = train_test_split(
    X_pad, y_int, test_size=0.30, random_state=SEED, stratify=y_int
)

# -----------------------------
# 6Ô∏è‚É£ Class weights
# -----------------------------
classes = np.unique(y_train)
cw = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)
class_weight = {int(c): float(w) for c, w in zip(classes, cw)}

# -----------------------------
# 7Ô∏è‚É£ Build RNN model
# -----------------------------
inp = layers.Input(shape=(SEQ_LEN,), dtype='int32')
x = layers.Embedding(input_dim=vocab_size, output_dim=EMB_DIM, mask_zero=True)(inp)
x = layers.SimpleRNN(RNN_UNITS)(x)
x = layers.Dropout(0.3)(x)
x = layers.Dense(64, activation='relu')(x)
x = layers.Dropout(0.15)(x)
out = layers.Dense(1, activation='sigmoid')(x)

model = models.Model(inputs=inp, outputs=out)
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# -----------------------------
# 8Ô∏è‚É£ Callbacks
# -----------------------------
ckpt_path = os.path.join(DATA_DIR, 'rnn_best.h5')
cb = [
    callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True),
    callbacks.ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True)
]

# -----------------------------
# 9Ô∏è‚É£ Train model
# -----------------------------
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    class_weight=class_weight,
    callbacks=cb,
    verbose=2
)

# -----------------------------
# üîü Metrics (Accuracy, Precision, Recall, F1)
# -----------------------------
y_train_pred = (model.predict(X_train) >= 0.5).astype(int).ravel()
y_val_pred   = (model.predict(X_val)   >= 0.5).astype(int).ravel()

metrics = {}
metrics['Train'] = {
    'Acc': accuracy_score(y_train, y_train_pred),
    'Precision': precision_score(y_train, y_train_pred, zero_division=0),
    'Recall': recall_score(y_train, y_train_pred, zero_division=0),
    'F1': f1_score(y_train, y_train_pred, zero_division=0)
}
metrics['Val'] = {
    'Acc': accuracy_score(y_val, y_val_pred),
    'Precision': precision_score(y_val, y_val_pred, zero_division=0),
    'Recall': recall_score(y_val, y_val_pred, zero_division=0),
    'F1': f1_score(y_val, y_val_pred, zero_division=0)
}

# -----------------------------
# 11Ô∏è‚É£ Print as table
# -----------------------------
table = pd.DataFrame(metrics).T
table = table[['Acc', 'Precision', 'Recall', 'F1']]
print("\nPerformance Table:\n")
print(table.to_string(float_format="{:.3f}".format))

import os
import random
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# -----------------------------
# 1Ô∏è‚É£ Set seeds
# -----------------------------
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# -----------------------------
# 2Ô∏è‚É£ Paths and Load CSV
# -----------------------------
DATA_DIR = '/content/drive2/MyDrive/IoTvulCode/data/iDetectRefine'
csv_path = os.path.join(DATA_DIR, 'DNN-binary.csv')
if not os.path.exists(csv_path):
    raise FileNotFoundError(f"Expected dataset at {csv_path}")

df = pd.read_csv(csv_path, low_memory=False)

# -----------------------------
# 3Ô∏è‚É£ Preprocessing
# -----------------------------
X_text = df.iloc[:, :-1].astype(str).agg(' '.join, axis=1)
y_raw = df.iloc[:, -1].values

# Clean text
X_text = X_text.str.replace(r'\r\n|\r|\n', ' ', regex=True)
X_text = X_text.str.replace(r'\s+', ' ', regex=True)
X_text = X_text.str.replace(r'([{}()\[\].,;:+\-*/=&|<>%!~^])', r' \1 ', regex=True)
X_text = X_text.str.lower()

# Label encode
le = LabelEncoder()
y_int = le.fit_transform(y_raw)
if len(np.unique(y_int)) != 2:
    raise ValueError("Expected binary classification labels but found multiple classes.")

# -----------------------------
# 4Ô∏è‚É£ Tokenization & Padding
# -----------------------------
MAX_WORDS = 60000
SEQ_LEN = 300
EMB_DIM = 128
BATCH_SIZE = 128
EPOCHS = 6

tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='[OOV]', filters='')
tokenizer.fit_on_texts(X_text)
sequences = tokenizer.texts_to_sequences(X_text)
X_pad = pad_sequences(sequences, maxlen=SEQ_LEN, padding='post', truncating='post')

vocab_size = min(MAX_WORDS, len(tokenizer.word_index) + 1)

# -----------------------------
# 5Ô∏è‚É£ Train/Validation split
# -----------------------------
X_train, X_val, y_train, y_val = train_test_split(
    X_pad, y_int, test_size=0.30, random_state=SEED, stratify=y_int
)

# -----------------------------
# 6Ô∏è‚É£ Class weights
# -----------------------------
classes = np.unique(y_train)
cw = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)
class_weight = {int(c): float(w) for c, w in zip(classes, cw)}

# -----------------------------
# 7Ô∏è‚É£ Build CNN Model
# -----------------------------
inp = layers.Input(shape=(SEQ_LEN,), dtype='int32')
x = layers.Embedding(input_dim=vocab_size, output_dim=EMB_DIM, mask_zero=True)(inp)
x = layers.Conv1D(filters=64, kernel_size=5, activation='relu')(x)
x = layers.MaxPooling1D(pool_size=2)(x)
x = layers.Conv1D(filters=32, kernel_size=3, activation='relu')(x)
x = layers.GlobalMaxPooling1D()(x)
x = layers.Dropout(0.4)(x)
x = layers.Dense(32, activation='relu')(x)
x = layers.Dropout(0.2)(x)
out = layers.Dense(1, activation='sigmoid')(x)

model = models.Model(inputs=inp, outputs=out)
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# -----------------------------
# 8Ô∏è‚É£ Callbacks
# -----------------------------
ckpt_path = os.path.join(DATA_DIR, 'cnn_best.h5')
cb = [
    callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True),
    callbacks.ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True)
]

# -----------------------------
# 9Ô∏è‚É£ Train the model
# -----------------------------
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    class_weight=class_weight,
    callbacks=cb,
    verbose=2
)

# -----------------------------
#  üîü Metrics
# -----------------------------
y_train_pred = (model.predict(X_train) >= 0.5).astype(int).ravel()
y_val_pred   = (model.predict(X_val)   >= 0.5).astype(int).ravel()

train_acc = accuracy_score(y_train, y_train_pred)
train_prec = precision_score(y_train, y_train_pred, zero_division=0)
train_rec  = recall_score(y_train, y_train_pred, zero_division=0)
train_f1   = f1_score(y_train, y_train_pred, zero_division=0)

val_acc = accuracy_score(y_val, y_val_pred)
val_prec = precision_score(y_val, y_val_pred, zero_division=0)
val_rec  = recall_score(y_val, y_val_pred, zero_division=0)
val_f1   = f1_score(y_val, y_val_pred, zero_division=0)

# -----------------------------
# 1Ô∏è‚É£1Ô∏è‚É£ Results Table
# -----------------------------
results = pd.DataFrame({
    'Set': ['Train', 'Val'],
    'Accuracy': [train_acc, val_acc],
    'Precision': [train_prec, val_prec],
    'Recall': [train_rec, val_rec],
    'F1': [train_f1, val_f1]
})

print("\nIoTvulCNN Model Performance:")
print(results.to_string(index=False))

import os
import random
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# -----------------------------
# 1Ô∏è‚É£ Set seeds
# -----------------------------
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# -----------------------------
# 2Ô∏è‚É£ Paths and Load CSV
# -----------------------------
DATA_DIR = '/content/drive2/MyDrive/IoTvulCode/data/iDetectRefine'
csv_path = os.path.join(DATA_DIR, 'DNN-binary.csv')
if not os.path.exists(csv_path):
    raise FileNotFoundError(f"Expected dataset at {csv_path}")

df = pd.read_csv(csv_path, low_memory=False)

# -----------------------------
# 3Ô∏è‚É£ Preprocessing
# -----------------------------
X_text = df.iloc[:, :-1].astype(str).agg(' '.join, axis=1)
y_raw = df.iloc[:, -1].values

X_text = X_text.str.replace(r'\r\n|\r|\n', ' ', regex=True)
X_text = X_text.str.replace(r'\s+', ' ', regex=True)
X_text = X_text.str.replace(r'([{}()\[\].,;:+\-*/=&|<>%!~^])', r' \1 ', regex=True)
X_text = X_text.str.lower()

# Label encode
le = LabelEncoder()
y_int = le.fit_transform(y_raw)
if len(np.unique(y_int)) != 2:
    raise ValueError("Expected binary classification labels but found multiple classes.")

# -----------------------------
# 4Ô∏è‚É£ Tokenization & Padding
# -----------------------------
MAX_WORDS = 60000
SEQ_LEN = 300
EMB_DIM = 128
RNN_UNITS = 128
BATCH_SIZE = 128
EPOCHS = 6

tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='[OOV]', filters='')
tokenizer.fit_on_texts(X_text)
sequences = tokenizer.texts_to_sequences(X_text)
X_pad = pad_sequences(sequences, maxlen=SEQ_LEN, padding='post', truncating='post')
vocab_size = min(MAX_WORDS, len(tokenizer.word_index) + 1)

# -----------------------------
# 5Ô∏è‚É£ Train/Validation split
# -----------------------------
X_train, X_val, y_train, y_val = train_test_split(
    X_pad, y_int, test_size=0.30, random_state=SEED, stratify=y_int
)

# -----------------------------
# 6Ô∏è‚É£ Class weights
# -----------------------------
classes = np.unique(y_train)
cw = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)
class_weight = {int(c): float(w) for c, w in zip(classes, cw)}

# -----------------------------
# 7Ô∏è‚É£ Build iDetect-RNN Model
# -----------------------------
inp = layers.Input(shape=(SEQ_LEN,), dtype='int32')
x = layers.Embedding(input_dim=vocab_size, output_dim=EMB_DIM, mask_zero=True)(inp)
x = layers.SimpleRNN(RNN_UNITS, return_sequences=False)(x)
x = layers.Dropout(0.3)(x)
x = layers.Dense(64, activation='relu')(x)
x = layers.Dropout(0.15)(x)
out = layers.Dense(1, activation='sigmoid')(x)

model = models.Model(inputs=inp, outputs=out)
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# -----------------------------
# 8Ô∏è‚É£ Callbacks
# -----------------------------
ckpt_path = os.path.join(DATA_DIR, 'rnn_best.h5')
cb = [
    callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True),
    callbacks.ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True)
]

# -----------------------------
# 9Ô∏è‚É£ Train the model
# -----------------------------
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    class_weight=class_weight,
    callbacks=cb,
    verbose=2
)

# -----------------------------
# üîü Metrics
# -----------------------------
y_train_pred = (model.predict(X_train) >= 0.5).astype(int).ravel()
y_val_pred   = (model.predict(X_val)   >= 0.5).astype(int).ravel()

train_acc = accuracy_score(y_train, y_train_pred)
train_prec = precision_score(y_train, y_train_pred, zero_division=0)
train_rec  = recall_score(y_train, y_train_pred, zero_division=0)
train_f1   = f1_score(y_train, y_train_pred, zero_division=0)

val_acc = accuracy_score(y_val, y_val_pred)
val_prec = precision_score(y_val, y_val_pred, zero_division=0)
val_rec  = recall_score(y_val, y_val_pred, zero_division=0)
val_f1   = f1_score(y_val, y_val_pred, zero_division=0)

# -----------------------------
# 1Ô∏è‚É£1Ô∏è‚É£ Results Table
# -----------------------------
results = pd.DataFrame({
    'Set': ['Train', 'Val'],
    'Accuracy': [train_acc, val_acc],
    'Precision': [train_prec, val_prec],
    'Recall': [train_rec, val_rec],
    'F1': [train_f1, val_f1]
})

print("\niDetect-RNN Model Performance:")
print(results.to_string(index=False))

import os
import random
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# -----------------------------
# Seeds for reproducibility
# -----------------------------
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# -----------------------------
# Paths
# -----------------------------
DATA_DIR = '/content/drive2/MyDrive/IoTvulCode/data/iDetectRefine'
csv_path = os.path.join(DATA_DIR, 'DNN-binary.csv')  # binary classification dataset
df = pd.read_csv(csv_path, low_memory=False)

# -----------------------------
# Preprocessing
# -----------------------------
X_text = df.iloc[:, :-1].astype(str).agg(' '.join, axis=1)
y_raw = df.iloc[:, -1].values

# Clean text similar to paper
X_text = X_text.str.replace(r'\r\n|\r|\n', ' ', regex=True)
X_text = X_text.str.replace(r'\s+', ' ', regex=True)
X_text = X_text.str.replace(r'([{}()\[\].,;:+\-*/=&|<>%!~^])', r' \1 ', regex=True)
X_text = X_text.str.lower()

# Label encode
le = LabelEncoder()
y_int = le.fit_transform(y_raw)
if len(np.unique(y_int)) != 2:
    raise ValueError("Expected binary classification labels but found multiple classes.")

# -----------------------------
# Tokenization & Padding
# -----------------------------
MAX_WORDS = 60000
SEQ_LEN = 300
EMB_DIM = 64  # smaller embedding
BATCH_SIZE = 128
EPOCHS = 6

tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='[OOV]', filters='')
tokenizer.fit_on_texts(X_text)
sequences = tokenizer.texts_to_sequences(X_text)
X_pad = pad_sequences(sequences, maxlen=SEQ_LEN, padding='post', truncating='post')

vocab_size = min(MAX_WORDS, len(tokenizer.word_index) + 1)

# -----------------------------
# Train/Validation split
# -----------------------------
X_train, X_val, y_train, y_val = train_test_split(
    X_pad, y_int, test_size=0.30, random_state=SEED, stratify=y_int
)

# -----------------------------
# Class weights
# -----------------------------
classes = np.unique(y_train)
cw = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)
class_weight = {int(c): float(w) for c, w in zip(classes, cw)}

# -----------------------------
# Build CNN Model
# -----------------------------
inp = layers.Input(shape=(SEQ_LEN,), dtype='int32')
x = layers.Embedding(input_dim=vocab_size, output_dim=EMB_DIM, mask_zero=False)(inp)
x = layers.SpatialDropout1D(0.4)(x)
x = layers.Conv1D(32, kernel_size=5, activation='relu', padding='same')(x)
x = layers.MaxPooling1D(pool_size=2)(x)
x = layers.Conv1D(32, kernel_size=3, activation='relu', padding='same')(x)
x = layers.GlobalMaxPooling1D()(x)
x = layers.Dropout(0.5)(x)
x = layers.Dense(32, activation='relu')(x)
x = layers.Dropout(0.25)(x)
out = layers.Dense(1, activation='sigmoid')(x)

model = models.Model(inputs=inp, outputs=out)
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# -----------------------------
# Callbacks
# -----------------------------
ckpt_path = os.path.join(DATA_DIR, 'cnn_best.h5')
cb = [
    callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True),
    callbacks.ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True)
]

# -----------------------------
# Training
# -----------------------------
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    class_weight=class_weight,
    callbacks=cb,
    verbose=2
)

# -----------------------------
# Metrics
# -----------------------------
y_train_pred = (model.predict(X_train) >= 0.5).astype(int).ravel()
y_val_pred   = (model.predict(X_val)   >= 0.5).astype(int).ravel()

train_acc = accuracy_score(y_train, y_train_pred)
train_prec = precision_score(y_train, y_train_pred, zero_division=0)
train_rec  = recall_score(y_train, y_train_pred, zero_division=0)
train_f1   = f1_score(y_train, y_train_pred, zero_division=0)

val_acc = accuracy_score(y_val, y_val_pred)
val_prec = precision_score(y_val, y_val_pred, zero_division=0)
val_rec  = recall_score(y_val, y_val_pred, zero_division=0)
val_f1   = f1_score(y_val, y_val_pred, zero_division=0)

# -----------------------------
# Print results as table
# -----------------------------
print("\nSet        Acc      Precision     Recall     F1")
print(f"Train   {train_acc:.3f}   {train_prec:.3f}       {train_rec:.3f}     {train_f1:.3f}")
print(f"Val     {val_acc:.3f}   {val_prec:.3f}       {val_rec:.3f}     {val_f1:.3f}")

import os
import random
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical

# -----------------------------
# Seeds
# -----------------------------
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# -----------------------------
# Paths
# -----------------------------
DATA_DIR = '/content/drive2/MyDrive/IoTvulCode/data/iDetectRefine'
csv_path = os.path.join(DATA_DIR, 'DNN-multiclass.csv')  # multi-class dataset
df = pd.read_csv(csv_path, low_memory=False)

# -----------------------------
# Preprocessing
# -----------------------------
X_text = df.iloc[:, :-1].astype(str).agg(' '.join, axis=1)
y_raw = df.iloc[:, -1].values

# Clean text
X_text = X_text.str.replace(r'\r\n|\r|\n', ' ', regex=True)
X_text = X_text.str.replace(r'\s+', ' ', regex=True)
X_text = X_text.str.replace(r'([{}()\[\].,;:+\-*/=&|<>%!~^])', r' \1 ', regex=True)
X_text = X_text.str.lower()

# Label encode
le = LabelEncoder()
y_int = le.fit_transform(y_raw)
num_classes = len(np.unique(y_int))
y_cat = to_categorical(y_int, num_classes=num_classes)

# -----------------------------
# Tokenization & Padding
# -----------------------------
MAX_WORDS = 60000
SEQ_LEN = 300
EMB_DIM = 128
RNN_UNITS = 128
BATCH_SIZE = 128
EPOCHS = 6

tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='[OOV]', filters='')
tokenizer.fit_on_texts(X_text)
sequences = tokenizer.texts_to_sequences(X_text)
X_pad = pad_sequences(sequences, maxlen=SEQ_LEN, padding='post', truncating='post')

vocab_size = min(MAX_WORDS, len(tokenizer.word_index) + 1)

# -----------------------------
# Train/Validation split
# -----------------------------
X_train, X_val, y_train, y_val = train_test_split(
    X_pad, y_cat, test_size=0.30, random_state=SEED, stratify=y_int
)

# -----------------------------
# Class weights
# -----------------------------
classes = np.unique(y_int)
cw = compute_class_weight(class_weight='balanced', classes=classes, y=y_int)
class_weight = {i: w for i, w in zip(classes, cw)}

# -----------------------------
# Build RNN Multi-class model
# -----------------------------
inp = layers.Input(shape=(SEQ_LEN,), dtype='int32')
x = layers.Embedding(input_dim=vocab_size, output_dim=EMB_DIM, mask_zero=True)(inp)
x = layers.SimpleRNN(RNN_UNITS)(x)
x = layers.Dropout(0.3)(x)
x = layers.Dense(64, activation='relu')(x)
x = layers.Dropout(0.15)(x)
out = layers.Dense(num_classes, activation='softmax')(x)

model = models.Model(inputs=inp, outputs=out)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# -----------------------------
# Callbacks
# -----------------------------
ckpt_path = os.path.join(DATA_DIR, 'rnnmul_best.h5')
cb = [
    callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True),
    callbacks.ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True)
]

# -----------------------------
# Training
# -----------------------------
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    class_weight=class_weight,
    callbacks=cb,
    verbose=2
)

# -----------------------------
# Metrics
# -----------------------------
y_train_pred = np.argmax(model.predict(X_train), axis=1)
y_val_pred   = np.argmax(model.predict(X_val), axis=1)
y_train_true = np.argmax(y_train, axis=1)
y_val_true   = np.argmax(y_val, axis=1)

train_acc = accuracy_score(y_train_true, y_train_pred)
train_prec = precision_score(y_train_true, y_train_pred, average='weighted', zero_division=0)
train_rec  = recall_score(y_train_true, y_train_pred, average='weighted', zero_division=0)
train_f1   = f1_score(y_train_true, y_train_pred, average='weighted', zero_division=0)

val_acc = accuracy_score(y_val_true, y_val_pred)
val_prec = precision_score(y_val_true, y_val_pred, average='weighted', zero_division=0)
val_rec  = recall_score(y_val_true, y_val_pred, average='weighted', zero_division=0)
val_f1   = f1_score(y_val_true, y_val_pred, average='weighted', zero_division=0)

# -----------------------------
# Print results table with label
# -----------------------------
print("\nModel: IoTvulCode-RNNmul")
print("Set        Acc      Precision     Recall     F1")
print(f"Train   {train_acc:.3f}   {train_prec:.3f}       {train_rec:.3f}     {train_f1:.3f}")
print(f"Val     {val_acc:.3f}   {val_prec:.3f}       {val_rec:.3f}     {val_f1:.3f}")

import os
import random
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical

# -----------------------------
# Seeds
# -----------------------------
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# -----------------------------
# Paths
# -----------------------------
DATA_DIR = '/content/drive2/MyDrive/IoTvulCode/data/iDetectRefine'
csv_path = os.path.join(DATA_DIR, 'DNN-multiclass.csv')  # multi-class dataset
df = pd.read_csv(csv_path, low_memory=False)

# -----------------------------
# Preprocessing
# -----------------------------
X_text = df.iloc[:, :-1].astype(str).agg(' '.join, axis=1)
y_raw = df.iloc[:, -1].values

# Clean text
X_text = X_text.str.replace(r'\r\n|\r|\n', ' ', regex=True)
X_text = X_text.str.replace(r'\s+', ' ', regex=True)
X_text = X_text.str.replace(r'([{}()\[\].,;:+\-*/=&|<>%!~^])', r' \1 ', regex=True)
X_text = X_text.str.lower()

# Label encode
le = LabelEncoder()
y_int = le.fit_transform(y_raw)
num_classes = len(np.unique(y_int))
y_cat = to_categorical(y_int, num_classes=num_classes)

# -----------------------------
# Tokenization & Padding
# -----------------------------
MAX_WORDS = 60000
SEQ_LEN = 300
EMB_DIM = 128
BATCH_SIZE = 128
EPOCHS = 6

tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='[OOV]', filters='')
tokenizer.fit_on_texts(X_text)
sequences = tokenizer.texts_to_sequences(X_text)
X_pad = pad_sequences(sequences, maxlen=SEQ_LEN, padding='post', truncating='post')

vocab_size = min(MAX_WORDS, len(tokenizer.word_index) + 1)

# -----------------------------
# Train/Validation split
# -----------------------------
X_train, X_val, y_train, y_val = train_test_split(
    X_pad, y_cat, test_size=0.30, random_state=SEED, stratify=y_int
)

# -----------------------------
# Class weights
# -----------------------------
classes = np.unique(y_int)
cw = compute_class_weight(class_weight='balanced', classes=classes, y=y_int)
class_weight = {i: w for i, w in zip(classes, cw)}

# -----------------------------
# Build CNN Multi-class model
# -----------------------------
inp = layers.Input(shape=(SEQ_LEN,), dtype='int32')
x = layers.Embedding(input_dim=vocab_size, output_dim=EMB_DIM, mask_zero=False)(inp)

# Multiple convolution filters (paper-style)
conv_filters = [3,4,5]
conv_layers = []
for f in conv_filters:
    c = layers.Conv1D(filters=128, kernel_size=f, activation='relu', padding='valid')(x)
    c = layers.GlobalMaxPooling1D()(c)
    conv_layers.append(c)

x = layers.concatenate(conv_layers)
x = layers.Dropout(0.3)(x)
x = layers.Dense(64, activation='relu')(x)
x = layers.Dropout(0.15)(x)
out = layers.Dense(num_classes, activation='softmax')(x)

model = models.Model(inputs=inp, outputs=out)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# -----------------------------
# Callbacks
# -----------------------------
ckpt_path = os.path.join(DATA_DIR, 'cnnmul_best.h5')
cb = [
    callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True),
    callbacks.ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True)
]

# -----------------------------
# Training
# -----------------------------
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    class_weight=class_weight,
    callbacks=cb,
    verbose=2
)

# -----------------------------
# Metrics
# -----------------------------
y_train_pred = np.argmax(model.predict(X_train), axis=1)
y_val_pred   = np.argmax(model.predict(X_val), axis=1)
y_train_true = np.argmax(y_train, axis=1)
y_val_true   = np.argmax(y_val, axis=1)

train_acc = accuracy_score(y_train_true, y_train_pred)
train_prec = precision_score(y_train_true, y_train_pred, average='weighted', zero_division=0)
train_rec  = recall_score(y_train_true, y_train_pred, average='weighted', zero_division=0)
train_f1   = f1_score(y_train_true, y_train_pred, average='weighted', zero_division=0)

val_acc = accuracy_score(y_val_true, y_val_pred)
val_prec = precision_score(y_val_true, y_val_pred, average='weighted', zero_division=0)
val_rec  = recall_score(y_val_true, y_val_pred, average='weighted', zero_division=0)
val_f1   = f1_score(y_val_true, y_val_pred, average='weighted', zero_division=0)

# -----------------------------
# Print results table with label
# -----------------------------
print("\nModel: IoTvulCode-CNNmul")
print("Set        Acc      Precision     Recall     F1")
print(f"Train   {train_acc:.3f}   {train_prec:.3f}       {train_rec:.3f}     {train_f1:.3f}")
print(f"Val     {val_acc:.3f}   {val_prec:.3f}       {val_rec:.3f}     {val_f1:.3f}")

# ==========================================
# üìà Final Model Performance Comparison (7 Models)
# ==========================================

import matplotlib.pyplot as plt
import numpy as np

# Model names
models = [
    "iotvul-RNN",
    "iotvul-CNN",
    "iDetect-RNN",
    "iDetect-CNN",
    "iotvul-RNNmulti",
    "iotvul-CNNmulti",
    "BiLSTM"
]

# -------------------------------------------------------
# üîπ Replace these accuracy/loss values with your real results
# (below are example values ‚Äî update them from your Colab output)
# -------------------------------------------------------
train_accuracy = [0.83, 0.87, 0.85, 0.88, 0.90, 0.92, 0.95]
val_accuracy   = [0.80, 0.85, 0.83, 0.86, 0.88, 0.91, 0.94]

train_loss = [0.30, 0.25, 0.27, 0.22, 0.18, 0.15, 0.10]
val_loss   = [0.34, 0.28, 0.31, 0.25, 0.20, 0.17, 0.12]

# ==========================================
# üìä BAR CHART: Accuracy Comparison
# ==========================================
x = np.arange(len(models))
width = 0.35

plt.figure(figsize=(11,6))
plt.bar(x - width/2, train_accuracy, width, label='Training Accuracy')
plt.bar(x + width/2, val_accuracy, width, label='Validation Accuracy')
plt.xlabel("Models")
plt.ylabel("Accuracy")
plt.title("Model Accuracy Comparison")
plt.xticks(x, models, rotation=25)
plt.legend()
plt.grid(True, axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# ==========================================
# üìâ BAR CHART: Loss Comparison
# ==========================================
plt.figure(figsize=(11,6))
plt.bar(x - width/2, train_loss, width, label='Training Loss')
plt.bar(x + width/2, val_loss, width, label='Validation Loss')
plt.xlabel("Models")
plt.ylabel("Loss")
plt.title("Model Loss Comparison")
plt.xticks(x, models, rotation=25)
plt.legend()
plt.grid(True, axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# ==========================================
# üìà LINE GRAPH: Accuracy Over Epochs (Example Trend)
# ==========================================
epochs = np.arange(1, 21)

# üîπ Replace these with your actual per-epoch accuracies if available
acc_iotvul_rnn = np.linspace(0.55, 0.83, 20)
acc_iotvul_cnn = np.linspace(0.60, 0.87, 20)
acc_idetect_rnn = np.linspace(0.58, 0.85, 20)
acc_idetect_cnn = np.linspace(0.63, 0.88, 20)
acc_iotvul_rnnmulti = np.linspace(0.65, 0.90, 20)
acc_iotvul_cnnmulti = np.linspace(0.68, 0.92, 20)
acc_bilstm = np.linspace(0.70, 0.95, 20)

plt.figure(figsize=(12,6))
plt.plot(epochs, acc_iotvul_rnn, label="iotvul-RNN")
plt.plot(epochs, acc_iotvul_cnn, label="iotvul-CNN")
plt.plot(epochs, acc_idetect_rnn, label="iDetect-RNN")
plt.plot(epochs, acc_idetect_cnn, label="iDetect-CNN")
plt.plot(epochs, acc_iotvul_rnnmulti, label="iotvul-RNNmulti")
plt.plot(epochs, acc_iotvul_cnnmulti, label="iotvul-CNNmulti")
plt.plot(epochs, acc_bilstm, label="BiLSTM", linewidth=2.5)
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("Training Accuracy per Epoch (All Models)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()